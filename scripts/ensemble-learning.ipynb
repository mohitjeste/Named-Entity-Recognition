{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the processed and cleaned sentences and tags\n",
    "sentences = np.load(os.path.join(DATA_DIR,\"processed_sents_dl.npy\"),allow_pickle=True)\n",
    "tags = np.load(os.path.join(DATA_DIR,\"processed_tags_dl.npy\"),allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we face a class imbalance problem for this task, one of the ways to mitigate it to use ensemble methods. We train a bunch of classifiers and then take the average of all the predictions from all classifiers. Our final prediction is the class with the highest probability from the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading glove embeddings\n",
    "embeddings_index = {}\n",
    "f = open(\"../embeddings/glove.6B.50d.txt\", encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.strip().split(' ')\n",
    "    word = values[0] # the first entry is the word\n",
    "    coefs = np.asarray(values[1:], dtype='float32') #50d vectors   \n",
    "    #representing the word\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the data set with X representing the corresponding word embedding for every word in the cleaned data\n",
    "#y are the BIO tags\n",
    "X=[]\n",
    "y=[]\n",
    "for i,sent in enumerate(sentences):\n",
    "    tag=tags[i]\n",
    "    for j,word in enumerate(sent):\n",
    "        currentTag = tag[j]\n",
    "        y.append(currentTag)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            X.append(embedding_vector)\n",
    "        else:\n",
    "            X.append([0]*EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y= np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34952, 50)\n",
      "(11651, 50)\n",
      "(34952,)\n",
      "(11651,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used knn, random forest, perceptron and the passive aggressive classifier as my individual models in the ensemble methods. Since the perceptron and passive aggressive classifier do not output class probabilities in sklearn I had to wrap them around a CalibratedClassifierCV to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred_knn = neigh.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=50)\n",
    "randomForest.fit(X_train, y_train)\n",
    "y_pred_rf = randomForest.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.60, NNZs: 50, Bias: -24.000000, T: 27961, Avg. loss: 0.073596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.14, NNZs: 50, Bias: -22.000000, T: 55922, Avg. loss: 0.080814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.04, NNZs: 50, Bias: -20.000000, T: 83883, Avg. loss: 0.079962\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.60, NNZs: 50, Bias: -21.000000, T: 111844, Avg. loss: 0.079043\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.67, NNZs: 50, Bias: -23.000000, T: 139805, Avg. loss: 0.079652\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.96, NNZs: 50, Bias: -28.000000, T: 167766, Avg. loss: 0.072823\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.53, NNZs: 50, Bias: -17.000000, T: 27961, Avg. loss: 0.065313\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.41, NNZs: 50, Bias: -20.000000, T: 55922, Avg. loss: 0.065487\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.65, NNZs: 50, Bias: -19.000000, T: 83883, Avg. loss: 0.067077\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.44, NNZs: 50, Bias: -19.000000, T: 111844, Avg. loss: 0.063258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.69, NNZs: 50, Bias: -19.000000, T: 139805, Avg. loss: 0.065533\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.77, NNZs: 50, Bias: -16.000000, T: 167766, Avg. loss: 0.066154\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 17.42, NNZs: 50, Bias: -19.000000, T: 195727, Avg. loss: 0.063570\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16.66, NNZs: 50, Bias: -18.000000, T: 223688, Avg. loss: 0.067344\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 16.62, NNZs: 50, Bias: -17.000000, T: 251649, Avg. loss: 0.066798\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 9 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.12, NNZs: 50, Bias: -19.000000, T: 27961, Avg. loss: 0.116978\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.21, NNZs: 50, Bias: -18.000000, T: 55922, Avg. loss: 0.122613\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.13, NNZs: 50, Bias: -21.000000, T: 83883, Avg. loss: 0.120157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.40, NNZs: 50, Bias: -13.000000, T: 111844, Avg. loss: 0.124151\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.75, NNZs: 50, Bias: -16.000000, T: 139805, Avg. loss: 0.120572\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.46, NNZs: 50, Bias: -15.000000, T: 167766, Avg. loss: 0.123393\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.04, NNZs: 50, Bias: -22.000000, T: 27961, Avg. loss: 0.218709\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.59, NNZs: 50, Bias: -24.000000, T: 55922, Avg. loss: 0.216795\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.33, NNZs: 50, Bias: -23.000000, T: 83883, Avg. loss: 0.226191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.18, NNZs: 50, Bias: -21.000000, T: 111844, Avg. loss: 0.220894\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.69, NNZs: 50, Bias: -15.000000, T: 139805, Avg. loss: 0.217233\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.90, NNZs: 50, Bias: -19.000000, T: 167766, Avg. loss: 0.230750\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 31.23, NNZs: 50, Bias: -21.000000, T: 195727, Avg. loss: 0.217934\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 22.85, NNZs: 50, Bias: -21.000000, T: 27961, Avg. loss: 0.197807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.57, NNZs: 50, Bias: -20.000000, T: 55922, Avg. loss: 0.201248\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.17, NNZs: 50, Bias: -20.000000, T: 83883, Avg. loss: 0.196705\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.21, NNZs: 50, Bias: -23.000000, T: 111844, Avg. loss: 0.200899\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.07, NNZs: 50, Bias: -24.000000, T: 139805, Avg. loss: 0.202394\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.13, NNZs: 50, Bias: -19.000000, T: 167766, Avg. loss: 0.199339\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 29.13, NNZs: 50, Bias: -19.000000, T: 195727, Avg. loss: 0.196103\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 33.68, NNZs: 50, Bias: -21.000000, T: 223688, Avg. loss: 0.192840\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 33.58, NNZs: 50, Bias: -21.000000, T: 251649, Avg. loss: 0.197419\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 35.41, NNZs: 50, Bias: -25.000000, T: 279610, Avg. loss: 0.190802\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.15, NNZs: 50, Bias: -22.000000, T: 307571, Avg. loss: 0.192490\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38.45, NNZs: 50, Bias: -20.000000, T: 335532, Avg. loss: 0.193636\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.57, NNZs: 50, Bias: -18.000000, T: 363493, Avg. loss: 0.199308\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 39.86, NNZs: 50, Bias: -18.000000, T: 391454, Avg. loss: 0.188613\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.21, NNZs: 50, Bias: -17.000000, T: 419415, Avg. loss: 0.185284\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.77, NNZs: 50, Bias: -22.000000, T: 447376, Avg. loss: 0.193350\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.00, NNZs: 50, Bias: -23.000000, T: 475337, Avg. loss: 0.194457\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.70, NNZs: 50, Bias: -22.000000, T: 503298, Avg. loss: 0.197010\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45.16, NNZs: 50, Bias: -20.000000, T: 531259, Avg. loss: 0.202323\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45.44, NNZs: 50, Bias: -21.000000, T: 559220, Avg. loss: 0.192883\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 20 epochs took 0.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.35, NNZs: 50, Bias: -23.000000, T: 27961, Avg. loss: 0.061103\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.64, NNZs: 50, Bias: -21.000000, T: 55922, Avg. loss: 0.063472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.84, NNZs: 50, Bias: -25.000000, T: 83883, Avg. loss: 0.058681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.25, NNZs: 50, Bias: -26.000000, T: 111844, Avg. loss: 0.060568\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.28, NNZs: 50, Bias: -24.000000, T: 139805, Avg. loss: 0.058054\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.82, NNZs: 50, Bias: -22.000000, T: 167766, Avg. loss: 0.058511\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21.91, NNZs: 50, Bias: -22.000000, T: 195727, Avg. loss: 0.059128\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 23.32, NNZs: 50, Bias: -20.000000, T: 223688, Avg. loss: 0.062160\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 8 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.67, NNZs: 50, Bias: -20.000000, T: 27961, Avg. loss: 0.021045\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.54, NNZs: 50, Bias: -25.000000, T: 55922, Avg. loss: 0.020666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.65, NNZs: 50, Bias: -26.000000, T: 83883, Avg. loss: 0.020853\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.26, NNZs: 50, Bias: -25.000000, T: 111844, Avg. loss: 0.021658\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.86, NNZs: 50, Bias: -25.000000, T: 139805, Avg. loss: 0.021788\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.60, NNZs: 50, Bias: -28.000000, T: 167766, Avg. loss: 0.022587\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.86, NNZs: 50, Bias: -24.000000, T: 27961, Avg. loss: 0.092213\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.31, NNZs: 50, Bias: -21.000000, T: 55922, Avg. loss: 0.099578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.86, NNZs: 50, Bias: -22.000000, T: 83883, Avg. loss: 0.099465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.77, NNZs: 50, Bias: -25.000000, T: 111844, Avg. loss: 0.094621\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.73, NNZs: 50, Bias: -21.000000, T: 139805, Avg. loss: 0.098169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.18, NNZs: 50, Bias: -21.000000, T: 167766, Avg. loss: 0.097804\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.94, NNZs: 50, Bias: -20.000000, T: 27961, Avg. loss: 0.083227\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 12.10, NNZs: 50, Bias: -21.000000, T: 55922, Avg. loss: 0.088342\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.55, NNZs: 50, Bias: -22.000000, T: 83883, Avg. loss: 0.082144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.20, NNZs: 50, Bias: -23.000000, T: 111844, Avg. loss: 0.089349\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.64, NNZs: 50, Bias: -22.000000, T: 139805, Avg. loss: 0.082687\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.99, NNZs: 50, Bias: -21.000000, T: 167766, Avg. loss: 0.087528\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.91, NNZs: 50, Bias: -23.000000, T: 195727, Avg. loss: 0.085445\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 18.87, NNZs: 50, Bias: -22.000000, T: 223688, Avg. loss: 0.088071\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.38, NNZs: 50, Bias: -29.000000, T: 27961, Avg. loss: 0.103785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.64, NNZs: 50, Bias: -28.000000, T: 55922, Avg. loss: 0.110463\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.96, NNZs: 50, Bias: -23.000000, T: 83883, Avg. loss: 0.116137\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.48, NNZs: 50, Bias: -25.000000, T: 111844, Avg. loss: 0.111530\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.55, NNZs: 50, Bias: -23.000000, T: 139805, Avg. loss: 0.109335\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.61, NNZs: 50, Bias: -25.000000, T: 167766, Avg. loss: 0.113037\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.38, NNZs: 50, Bias: -22.000000, T: 27961, Avg. loss: 0.132679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.37, NNZs: 50, Bias: -18.000000, T: 55922, Avg. loss: 0.134833\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.33, NNZs: 50, Bias: -19.000000, T: 83883, Avg. loss: 0.137741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.90, NNZs: 50, Bias: -17.000000, T: 111844, Avg. loss: 0.135150\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.32, NNZs: 50, Bias: -21.000000, T: 139805, Avg. loss: 0.133563\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.17, NNZs: 50, Bias: -25.000000, T: 167766, Avg. loss: 0.137149\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.71, NNZs: 50, Bias: -20.000000, T: 27961, Avg. loss: 0.085351\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.98, NNZs: 50, Bias: -20.000000, T: 55922, Avg. loss: 0.084532\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.09, NNZs: 50, Bias: -23.000000, T: 83883, Avg. loss: 0.084352\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.92, NNZs: 50, Bias: -21.000000, T: 111844, Avg. loss: 0.084531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.28, NNZs: 50, Bias: -19.000000, T: 139805, Avg. loss: 0.084107\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.54, NNZs: 50, Bias: -23.000000, T: 167766, Avg. loss: 0.083613\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 28.94, NNZs: 50, Bias: 4.000000, T: 27961, Avg. loss: 0.970486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.92, NNZs: 50, Bias: 5.000000, T: 55922, Avg. loss: 0.975812\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.94, NNZs: 50, Bias: 3.000000, T: 83883, Avg. loss: 0.984499\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.39, NNZs: 50, Bias: 3.000000, T: 111844, Avg. loss: 0.963170\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 45.56, NNZs: 50, Bias: 2.000000, T: 139805, Avg. loss: 0.970507\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.26, NNZs: 50, Bias: 4.000000, T: 167766, Avg. loss: 0.970020\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.21, NNZs: 50, Bias: 5.000000, T: 195727, Avg. loss: 0.975921\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.37, NNZs: 50, Bias: 6.000000, T: 223688, Avg. loss: 0.978046\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 48.11, NNZs: 50, Bias: 1.000000, T: 251649, Avg. loss: 0.966623\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 9 epochs took 0.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 18.62, NNZs: 50, Bias: -25.000000, T: 27961, Avg. loss: 0.076488\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.23, NNZs: 50, Bias: -23.000000, T: 55922, Avg. loss: 0.076380\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.42, NNZs: 50, Bias: -24.000000, T: 83883, Avg. loss: 0.077738\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.98, NNZs: 50, Bias: -22.000000, T: 111844, Avg. loss: 0.080466\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.85, NNZs: 50, Bias: -21.000000, T: 139805, Avg. loss: 0.078993\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.13, NNZs: 50, Bias: -25.000000, T: 167766, Avg. loss: 0.075402\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.15, NNZs: 50, Bias: -13.000000, T: 27961, Avg. loss: 0.065231\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.51, NNZs: 50, Bias: -19.000000, T: 55922, Avg. loss: 0.062996\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.19, NNZs: 50, Bias: -22.000000, T: 83883, Avg. loss: 0.065695\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.79, NNZs: 50, Bias: -21.000000, T: 111844, Avg. loss: 0.066664\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.73, NNZs: 50, Bias: -20.000000, T: 139805, Avg. loss: 0.065817\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.63, NNZs: 50, Bias: -20.000000, T: 167766, Avg. loss: 0.064456\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.15, NNZs: 50, Bias: -19.000000, T: 195727, Avg. loss: 0.064417\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 7 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.46, NNZs: 50, Bias: -18.000000, T: 27961, Avg. loss: 0.122350\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.12, NNZs: 50, Bias: -19.000000, T: 55922, Avg. loss: 0.125321\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.79, NNZs: 50, Bias: -21.000000, T: 83883, Avg. loss: 0.124377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.74, NNZs: 50, Bias: -19.000000, T: 111844, Avg. loss: 0.122370\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.13, NNZs: 50, Bias: -19.000000, T: 139805, Avg. loss: 0.115209\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.14, NNZs: 50, Bias: -18.000000, T: 167766, Avg. loss: 0.122191\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.02, NNZs: 50, Bias: -19.000000, T: 195727, Avg. loss: 0.120644\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 20.97, NNZs: 50, Bias: -17.000000, T: 223688, Avg. loss: 0.122355\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 18.72, NNZs: 50, Bias: -18.000000, T: 251649, Avg. loss: 0.124338\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 20.99, NNZs: 50, Bias: -18.000000, T: 279610, Avg. loss: 0.123897\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 10 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.43, NNZs: 50, Bias: -21.000000, T: 27961, Avg. loss: 0.220090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.69, NNZs: 50, Bias: -21.000000, T: 55922, Avg. loss: 0.223987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.96, NNZs: 50, Bias: -20.000000, T: 83883, Avg. loss: 0.235380\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.20, NNZs: 50, Bias: -20.000000, T: 111844, Avg. loss: 0.229862\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.97, NNZs: 50, Bias: -20.000000, T: 139805, Avg. loss: 0.218498\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29.83, NNZs: 50, Bias: -19.000000, T: 167766, Avg. loss: 0.227971\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 30.20, NNZs: 50, Bias: -18.000000, T: 195727, Avg. loss: 0.220238\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 34.69, NNZs: 50, Bias: -20.000000, T: 223688, Avg. loss: 0.222405\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 34.01, NNZs: 50, Bias: -20.000000, T: 251649, Avg. loss: 0.223343\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 35.22, NNZs: 50, Bias: -20.000000, T: 279610, Avg. loss: 0.219983\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 10 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.14, NNZs: 50, Bias: -18.000000, T: 27961, Avg. loss: 0.187989\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.49, NNZs: 50, Bias: -19.000000, T: 55922, Avg. loss: 0.201192\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.48, NNZs: 50, Bias: -20.000000, T: 83883, Avg. loss: 0.197915\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.06, NNZs: 50, Bias: -19.000000, T: 111844, Avg. loss: 0.193494\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.28, NNZs: 50, Bias: -17.000000, T: 139805, Avg. loss: 0.201540\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.54, NNZs: 50, Bias: -16.000000, T: 167766, Avg. loss: 0.192441\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.48, NNZs: 50, Bias: -24.000000, T: 27961, Avg. loss: 0.057376\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.70, NNZs: 50, Bias: -23.000000, T: 55922, Avg. loss: 0.056501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.09, NNZs: 50, Bias: -24.000000, T: 83883, Avg. loss: 0.055926\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.29, NNZs: 50, Bias: -26.000000, T: 111844, Avg. loss: 0.054360\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.07, NNZs: 50, Bias: -23.000000, T: 139805, Avg. loss: 0.057240\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.39, NNZs: 50, Bias: -25.000000, T: 167766, Avg. loss: 0.055267\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.70, NNZs: 50, Bias: -27.000000, T: 195727, Avg. loss: 0.056081\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 18.89, NNZs: 50, Bias: -26.000000, T: 223688, Avg. loss: 0.056147\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 20.60, NNZs: 50, Bias: -22.000000, T: 251649, Avg. loss: 0.055605\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 9 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.52, NNZs: 50, Bias: -21.000000, T: 27961, Avg. loss: 0.022055\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.50, NNZs: 50, Bias: -24.000000, T: 55922, Avg. loss: 0.019927\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.37, NNZs: 50, Bias: -27.000000, T: 83883, Avg. loss: 0.020774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.24, NNZs: 50, Bias: -28.000000, T: 111844, Avg. loss: 0.019178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.65, NNZs: 50, Bias: -28.000000, T: 139805, Avg. loss: 0.019172\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.79, NNZs: 50, Bias: -28.000000, T: 167766, Avg. loss: 0.021700\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 17.27, NNZs: 50, Bias: -30.000000, T: 195727, Avg. loss: 0.021496\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.10, NNZs: 50, Bias: -25.000000, T: 27961, Avg. loss: 0.094525\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.98, NNZs: 50, Bias: -23.000000, T: 55922, Avg. loss: 0.098306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.80, NNZs: 50, Bias: -25.000000, T: 83883, Avg. loss: 0.100931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.45, NNZs: 50, Bias: -23.000000, T: 111844, Avg. loss: 0.100550\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 15.64, NNZs: 50, Bias: -26.000000, T: 139805, Avg. loss: 0.094701\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.51, NNZs: 50, Bias: -23.000000, T: 167766, Avg. loss: 0.100928\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.83, NNZs: 50, Bias: -22.000000, T: 27961, Avg. loss: 0.082798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.96, NNZs: 50, Bias: -23.000000, T: 55922, Avg. loss: 0.083402\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.69, NNZs: 50, Bias: -24.000000, T: 83883, Avg. loss: 0.086077\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.99, NNZs: 50, Bias: -23.000000, T: 111844, Avg. loss: 0.083772\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.44, NNZs: 50, Bias: -22.000000, T: 139805, Avg. loss: 0.082921\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.58, NNZs: 50, Bias: -20.000000, T: 167766, Avg. loss: 0.083868\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 17.23, NNZs: 50, Bias: -26.000000, T: 27961, Avg. loss: 0.109057\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.24, NNZs: 50, Bias: -26.000000, T: 55922, Avg. loss: 0.114295\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.65, NNZs: 50, Bias: -23.000000, T: 83883, Avg. loss: 0.113157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.99, NNZs: 50, Bias: -28.000000, T: 111844, Avg. loss: 0.113466\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.66, NNZs: 50, Bias: -26.000000, T: 139805, Avg. loss: 0.110107\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.99, NNZs: 50, Bias: -26.000000, T: 167766, Avg. loss: 0.109766\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.32, NNZs: 50, Bias: -19.000000, T: 27961, Avg. loss: 0.138099\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.86, NNZs: 50, Bias: -17.000000, T: 55922, Avg. loss: 0.139387\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.20, NNZs: 50, Bias: -19.000000, T: 83883, Avg. loss: 0.137527\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.62, NNZs: 50, Bias: -18.000000, T: 111844, Avg. loss: 0.135655\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.46, NNZs: 50, Bias: -18.000000, T: 139805, Avg. loss: 0.141272\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.73, NNZs: 50, Bias: -21.000000, T: 167766, Avg. loss: 0.136496\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.47, NNZs: 50, Bias: -22.000000, T: 195727, Avg. loss: 0.145581\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 25.51, NNZs: 50, Bias: -17.000000, T: 223688, Avg. loss: 0.139908\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 24.80, NNZs: 50, Bias: -18.000000, T: 251649, Avg. loss: 0.141574\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 9 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.28, NNZs: 50, Bias: -18.000000, T: 27961, Avg. loss: 0.083757\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.18, NNZs: 50, Bias: -21.000000, T: 55922, Avg. loss: 0.083011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.30, NNZs: 50, Bias: -20.000000, T: 83883, Avg. loss: 0.083861\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.49, NNZs: 50, Bias: -23.000000, T: 111844, Avg. loss: 0.082430\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.43, NNZs: 50, Bias: -23.000000, T: 139805, Avg. loss: 0.084873\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.59, NNZs: 50, Bias: -22.000000, T: 167766, Avg. loss: 0.087027\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 30.20, NNZs: 50, Bias: 5.000000, T: 27961, Avg. loss: 1.003570\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.48, NNZs: 50, Bias: 7.000000, T: 55922, Avg. loss: 0.971578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.50, NNZs: 50, Bias: 6.000000, T: 83883, Avg. loss: 0.976094\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.59, NNZs: 50, Bias: 2.000000, T: 111844, Avg. loss: 0.954538\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.48, NNZs: 50, Bias: 3.000000, T: 139805, Avg. loss: 0.975121\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.37, NNZs: 50, Bias: 2.000000, T: 167766, Avg. loss: 0.945805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.14, NNZs: 50, Bias: 1.000000, T: 195727, Avg. loss: 0.969518\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.06, NNZs: 50, Bias: 2.000000, T: 223688, Avg. loss: 0.974981\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.13, NNZs: 50, Bias: 4.000000, T: 251649, Avg. loss: 0.979095\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 55.89, NNZs: 50, Bias: 4.000000, T: 279610, Avg. loss: 0.982427\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.45, NNZs: 50, Bias: 5.000000, T: 307571, Avg. loss: 0.975762\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 11 epochs took 0.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 19.73, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.082932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.36, NNZs: 50, Bias: -23.000000, T: 55924, Avg. loss: 0.081939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.50, NNZs: 50, Bias: -22.000000, T: 83886, Avg. loss: 0.080901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.81, NNZs: 50, Bias: -24.000000, T: 111848, Avg. loss: 0.080510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.74, NNZs: 50, Bias: -23.000000, T: 139810, Avg. loss: 0.083768\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.34, NNZs: 50, Bias: -23.000000, T: 167772, Avg. loss: 0.080411\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.74, NNZs: 50, Bias: -25.000000, T: 195734, Avg. loss: 0.080871\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 22.22, NNZs: 50, Bias: -19.000000, T: 223696, Avg. loss: 0.081983\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.98, NNZs: 50, Bias: -23.000000, T: 27962, Avg. loss: 0.064633\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.47, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.066117\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.96, NNZs: 50, Bias: -18.000000, T: 83886, Avg. loss: 0.068462\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.12, NNZs: 50, Bias: -20.000000, T: 111848, Avg. loss: 0.069132\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.28, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.067190\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.30, NNZs: 50, Bias: -24.000000, T: 167772, Avg. loss: 0.066477\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.77, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.122600\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.80, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.124858\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.11, NNZs: 50, Bias: -16.000000, T: 83886, Avg. loss: 0.120889\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.65, NNZs: 50, Bias: -16.000000, T: 111848, Avg. loss: 0.121510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.80, NNZs: 50, Bias: -18.000000, T: 139810, Avg. loss: 0.125864\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.84, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.123208\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21.63, NNZs: 50, Bias: -18.000000, T: 195734, Avg. loss: 0.121701\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21.12, NNZs: 50, Bias: -17.000000, T: 223696, Avg. loss: 0.121470\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 8 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 17.96, NNZs: 50, Bias: -19.000000, T: 27962, Avg. loss: 0.229153\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.05, NNZs: 50, Bias: -21.000000, T: 55924, Avg. loss: 0.219952\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.34, NNZs: 50, Bias: -21.000000, T: 83886, Avg. loss: 0.217640\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.98, NNZs: 50, Bias: -16.000000, T: 111848, Avg. loss: 0.228575\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.02, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.225244\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.80, NNZs: 50, Bias: -21.000000, T: 167772, Avg. loss: 0.218251\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 33.01, NNZs: 50, Bias: -24.000000, T: 195734, Avg. loss: 0.227791\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.16, NNZs: 50, Bias: -19.000000, T: 223696, Avg. loss: 0.223197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.45, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.186506\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.89, NNZs: 50, Bias: -23.000000, T: 55924, Avg. loss: 0.199105\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.28, NNZs: 50, Bias: -19.000000, T: 83886, Avg. loss: 0.190756\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.93, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.191049\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.03, NNZs: 50, Bias: -25.000000, T: 139810, Avg. loss: 0.188767\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.18, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.195769\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.79, NNZs: 50, Bias: -24.000000, T: 27962, Avg. loss: 0.057178\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.75, NNZs: 50, Bias: -24.000000, T: 55924, Avg. loss: 0.058081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.33, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.060979\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.72, NNZs: 50, Bias: -27.000000, T: 111848, Avg. loss: 0.056717\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.31, NNZs: 50, Bias: -26.000000, T: 139810, Avg. loss: 0.061402\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.58, NNZs: 50, Bias: -25.000000, T: 167772, Avg. loss: 0.062808\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.82, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.020892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.20, NNZs: 50, Bias: -22.000000, T: 55924, Avg. loss: 0.022234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.92, NNZs: 50, Bias: -23.000000, T: 83886, Avg. loss: 0.021349\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.10, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.023163\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.28, NNZs: 50, Bias: -24.000000, T: 139810, Avg. loss: 0.020572\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.98, NNZs: 50, Bias: -23.000000, T: 167772, Avg. loss: 0.020507\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.56, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.093232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.33, NNZs: 50, Bias: -22.000000, T: 55924, Avg. loss: 0.098179\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.00, NNZs: 50, Bias: -24.000000, T: 83886, Avg. loss: 0.096832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.67, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.099371\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.82, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.094502\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.22, NNZs: 50, Bias: -23.000000, T: 167772, Avg. loss: 0.097889\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.67, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.080479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.00, NNZs: 50, Bias: -23.000000, T: 55924, Avg. loss: 0.084850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.73, NNZs: 50, Bias: -26.000000, T: 83886, Avg. loss: 0.082896\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.57, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.082054\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.80, NNZs: 50, Bias: -25.000000, T: 139810, Avg. loss: 0.085764\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.99, NNZs: 50, Bias: -24.000000, T: 167772, Avg. loss: 0.086522\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.96, NNZs: 50, Bias: -25.000000, T: 27962, Avg. loss: 0.104696\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.07, NNZs: 50, Bias: -28.000000, T: 55924, Avg. loss: 0.116552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.60, NNZs: 50, Bias: -27.000000, T: 83886, Avg. loss: 0.108884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.75, NNZs: 50, Bias: -27.000000, T: 111848, Avg. loss: 0.112195\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 17.59, NNZs: 50, Bias: -25.000000, T: 139810, Avg. loss: 0.107970\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.99, NNZs: 50, Bias: -26.000000, T: 167772, Avg. loss: 0.106328\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.83, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.137189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.26, NNZs: 50, Bias: -19.000000, T: 55924, Avg. loss: 0.133075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.50, NNZs: 50, Bias: -22.000000, T: 83886, Avg. loss: 0.133954\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.54, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.133343\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.06, NNZs: 50, Bias: -17.000000, T: 139810, Avg. loss: 0.136895\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25.93, NNZs: 50, Bias: -16.000000, T: 167772, Avg. loss: 0.134856\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.62, NNZs: 50, Bias: -16.000000, T: 195734, Avg. loss: 0.138352\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 7 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.56, NNZs: 50, Bias: -25.000000, T: 27962, Avg. loss: 0.080923\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.75, NNZs: 50, Bias: -19.000000, T: 55924, Avg. loss: 0.088665\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.10, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.087623\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.23, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.086192\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.41, NNZs: 50, Bias: -25.000000, T: 139810, Avg. loss: 0.085661\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.91, NNZs: 50, Bias: -21.000000, T: 167772, Avg. loss: 0.084198\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 27.82, NNZs: 50, Bias: 10.000000, T: 27962, Avg. loss: 0.957093\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.17, NNZs: 50, Bias: 5.000000, T: 55924, Avg. loss: 0.941141\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.72, NNZs: 50, Bias: 5.000000, T: 83886, Avg. loss: 0.951395\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.46, NNZs: 50, Bias: 1.000000, T: 111848, Avg. loss: 0.952043\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.21, NNZs: 50, Bias: 6.000000, T: 139810, Avg. loss: 0.956441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.18, NNZs: 50, Bias: 4.000000, T: 167772, Avg. loss: 0.940204\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 46.99, NNZs: 50, Bias: 4.000000, T: 195734, Avg. loss: 0.960955\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 7 epochs took 0.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.38, NNZs: 50, Bias: -24.000000, T: 27962, Avg. loss: 0.077575\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.02, NNZs: 50, Bias: -25.000000, T: 55924, Avg. loss: 0.080674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.06, NNZs: 50, Bias: -24.000000, T: 83886, Avg. loss: 0.077369\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 22.44, NNZs: 50, Bias: -26.000000, T: 111848, Avg. loss: 0.084176\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.32, NNZs: 50, Bias: -24.000000, T: 139810, Avg. loss: 0.078185\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.32, NNZs: 50, Bias: -22.000000, T: 167772, Avg. loss: 0.079156\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.11, NNZs: 50, Bias: -17.000000, T: 27962, Avg. loss: 0.066714\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.44, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.066477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.73, NNZs: 50, Bias: -17.000000, T: 83886, Avg. loss: 0.067178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.45, NNZs: 50, Bias: -19.000000, T: 111848, Avg. loss: 0.065880\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.69, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.068055\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.18, NNZs: 50, Bias: -22.000000, T: 167772, Avg. loss: 0.063396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 14.85, NNZs: 50, Bias: -21.000000, T: 195734, Avg. loss: 0.067770\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 15.96, NNZs: 50, Bias: -20.000000, T: 223696, Avg. loss: 0.065073\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 14.69, NNZs: 50, Bias: -21.000000, T: 251658, Avg. loss: 0.066623\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 17.28, NNZs: 50, Bias: -19.000000, T: 279620, Avg. loss: 0.067730\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 15.45, NNZs: 50, Bias: -16.000000, T: 307582, Avg. loss: 0.069136\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 11 epochs took 0.07 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.75, NNZs: 50, Bias: -19.000000, T: 27962, Avg. loss: 0.116828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.59, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.122614\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.45, NNZs: 50, Bias: -17.000000, T: 83886, Avg. loss: 0.126547\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.11, NNZs: 50, Bias: -19.000000, T: 111848, Avg. loss: 0.122283\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.60, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.114644\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.38, NNZs: 50, Bias: -15.000000, T: 167772, Avg. loss: 0.122077\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 23.02, NNZs: 50, Bias: -19.000000, T: 195734, Avg. loss: 0.122800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21.03, NNZs: 50, Bias: -23.000000, T: 223696, Avg. loss: 0.125174\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 25.11, NNZs: 50, Bias: -13.000000, T: 251658, Avg. loss: 0.123487\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 23.31, NNZs: 50, Bias: -15.000000, T: 279620, Avg. loss: 0.118493\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 10 epochs took 0.07 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.47, NNZs: 50, Bias: -17.000000, T: 27962, Avg. loss: 0.220132\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.26, NNZs: 50, Bias: -21.000000, T: 55924, Avg. loss: 0.212491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.39, NNZs: 50, Bias: -22.000000, T: 83886, Avg. loss: 0.233046\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 22.62, NNZs: 50, Bias: -15.000000, T: 111848, Avg. loss: 0.231130\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.45, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.225840\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.61, NNZs: 50, Bias: -18.000000, T: 167772, Avg. loss: 0.228209\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.38, NNZs: 50, Bias: -19.000000, T: 195734, Avg. loss: 0.230909\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 7 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 22.81, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.194912\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.22, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.193887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.95, NNZs: 50, Bias: -21.000000, T: 83886, Avg. loss: 0.195585\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.48, NNZs: 50, Bias: -20.000000, T: 111848, Avg. loss: 0.195728\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.69, NNZs: 50, Bias: -25.000000, T: 139810, Avg. loss: 0.187860\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.66, NNZs: 50, Bias: -24.000000, T: 167772, Avg. loss: 0.194968\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 29.37, NNZs: 50, Bias: -19.000000, T: 195734, Avg. loss: 0.197134\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 32.12, NNZs: 50, Bias: -17.000000, T: 223696, Avg. loss: 0.194694\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 33.76, NNZs: 50, Bias: -19.000000, T: 251658, Avg. loss: 0.193249\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 34.74, NNZs: 50, Bias: -23.000000, T: 279620, Avg. loss: 0.189358\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 10 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.29, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.057036\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.41, NNZs: 50, Bias: -21.000000, T: 55924, Avg. loss: 0.056027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.11, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.054653\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.05, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.058131\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.01, NNZs: 50, Bias: -27.000000, T: 139810, Avg. loss: 0.052384\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.13, NNZs: 50, Bias: -25.000000, T: 167772, Avg. loss: 0.058524\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.52, NNZs: 50, Bias: -24.000000, T: 195734, Avg. loss: 0.058466\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 19.15, NNZs: 50, Bias: -26.000000, T: 223696, Avg. loss: 0.059068\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 23.67, NNZs: 50, Bias: -25.000000, T: 251658, Avg. loss: 0.056903\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 20.29, NNZs: 50, Bias: -25.000000, T: 279620, Avg. loss: 0.059846\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 10 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.57, NNZs: 50, Bias: -21.000000, T: 27962, Avg. loss: 0.019527\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.81, NNZs: 50, Bias: -25.000000, T: 55924, Avg. loss: 0.021496\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.46, NNZs: 50, Bias: -25.000000, T: 83886, Avg. loss: 0.022811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.21, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.023841\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.47, NNZs: 50, Bias: -24.000000, T: 139810, Avg. loss: 0.022878\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.31, NNZs: 50, Bias: -27.000000, T: 167772, Avg. loss: 0.022743\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.96, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.096673\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.14, NNZs: 50, Bias: -19.000000, T: 55924, Avg. loss: 0.100361\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.05, NNZs: 50, Bias: -22.000000, T: 83886, Avg. loss: 0.099210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.70, NNZs: 50, Bias: -21.000000, T: 111848, Avg. loss: 0.099881\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.84, NNZs: 50, Bias: -21.000000, T: 139810, Avg. loss: 0.098259\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.29, NNZs: 50, Bias: -23.000000, T: 167772, Avg. loss: 0.095255\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16.21, NNZs: 50, Bias: -20.000000, T: 195734, Avg. loss: 0.098444\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13.36, NNZs: 50, Bias: -22.000000, T: 223696, Avg. loss: 0.099438\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 16.16, NNZs: 50, Bias: -23.000000, T: 251658, Avg. loss: 0.095974\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 15.21, NNZs: 50, Bias: -22.000000, T: 279620, Avg. loss: 0.102355\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 17.34, NNZs: 50, Bias: -22.000000, T: 307582, Avg. loss: 0.097304\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 11 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.40, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.082682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.64, NNZs: 50, Bias: -20.000000, T: 55924, Avg. loss: 0.084699\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.85, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.083070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.85, NNZs: 50, Bias: -20.000000, T: 111848, Avg. loss: 0.084837\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.76, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.084974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.14, NNZs: 50, Bias: -18.000000, T: 167772, Avg. loss: 0.083655\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.95, NNZs: 50, Bias: -26.000000, T: 27962, Avg. loss: 0.105393\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.42, NNZs: 50, Bias: -29.000000, T: 55924, Avg. loss: 0.107051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.06, NNZs: 50, Bias: -31.000000, T: 83886, Avg. loss: 0.112523\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.17, NNZs: 50, Bias: -27.000000, T: 111848, Avg. loss: 0.109863\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.28, NNZs: 50, Bias: -27.000000, T: 139810, Avg. loss: 0.118380\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.29, NNZs: 50, Bias: -28.000000, T: 167772, Avg. loss: 0.104080\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.80, NNZs: 50, Bias: -28.000000, T: 195734, Avg. loss: 0.114816\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21.50, NNZs: 50, Bias: -27.000000, T: 223696, Avg. loss: 0.110411\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 23.01, NNZs: 50, Bias: -27.000000, T: 251658, Avg. loss: 0.111438\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 21.44, NNZs: 50, Bias: -26.000000, T: 279620, Avg. loss: 0.111745\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 22.31, NNZs: 50, Bias: -26.000000, T: 307582, Avg. loss: 0.111408\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 11 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.02, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.129260\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.21, NNZs: 50, Bias: -24.000000, T: 55924, Avg. loss: 0.129939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.94, NNZs: 50, Bias: -19.000000, T: 83886, Avg. loss: 0.136734\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.46, NNZs: 50, Bias: -18.000000, T: 111848, Avg. loss: 0.136549\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.52, NNZs: 50, Bias: -17.000000, T: 139810, Avg. loss: 0.136239\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.35, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.135767\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.87, NNZs: 50, Bias: -24.000000, T: 27962, Avg. loss: 0.085151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.60, NNZs: 50, Bias: -19.000000, T: 55924, Avg. loss: 0.088308\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.88, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.089129\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.18, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.085764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.88, NNZs: 50, Bias: -23.000000, T: 139810, Avg. loss: 0.087172\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.41, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.087530\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 29.88, NNZs: 50, Bias: 6.000000, T: 27962, Avg. loss: 0.963182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.67, NNZs: 50, Bias: 4.000000, T: 55924, Avg. loss: 0.966625\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.52, NNZs: 50, Bias: 7.000000, T: 83886, Avg. loss: 0.973724\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.13, NNZs: 50, Bias: 1.000000, T: 111848, Avg. loss: 0.969164\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.79, NNZs: 50, Bias: 7.000000, T: 139810, Avg. loss: 0.970889\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.49, NNZs: 50, Bias: 4.000000, T: 167772, Avg. loss: 0.965788\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm: 19.48, NNZs: 50, Bias: -21.000000, T: 27962, Avg. loss: 0.079966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.18, NNZs: 50, Bias: -24.000000, T: 55924, Avg. loss: 0.078500\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.68, NNZs: 50, Bias: -24.000000, T: 83886, Avg. loss: 0.073171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.17, NNZs: 50, Bias: -28.000000, T: 111848, Avg. loss: 0.079827\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.81, NNZs: 50, Bias: -24.000000, T: 139810, Avg. loss: 0.081385\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.41, NNZs: 50, Bias: -25.000000, T: 167772, Avg. loss: 0.082399\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 23.68, NNZs: 50, Bias: -29.000000, T: 195734, Avg. loss: 0.078714\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 25.04, NNZs: 50, Bias: -24.000000, T: 223696, Avg. loss: 0.084918\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.65, NNZs: 50, Bias: -19.000000, T: 27962, Avg. loss: 0.063890\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.97, NNZs: 50, Bias: -16.000000, T: 55924, Avg. loss: 0.067554\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.38, NNZs: 50, Bias: -17.000000, T: 83886, Avg. loss: 0.070138\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.54, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.066505\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.63, NNZs: 50, Bias: -18.000000, T: 139810, Avg. loss: 0.067067\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.45, NNZs: 50, Bias: -19.000000, T: 167772, Avg. loss: 0.067332\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.87, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.117225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.22, NNZs: 50, Bias: -21.000000, T: 55924, Avg. loss: 0.123439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.38, NNZs: 50, Bias: -16.000000, T: 83886, Avg. loss: 0.123611\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.83, NNZs: 50, Bias: -18.000000, T: 111848, Avg. loss: 0.119906\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.76, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.115995\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.06, NNZs: 50, Bias: -15.000000, T: 167772, Avg. loss: 0.119032\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.03, NNZs: 50, Bias: -20.000000, T: 195734, Avg. loss: 0.121953\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21.09, NNZs: 50, Bias: -20.000000, T: 223696, Avg. loss: 0.123432\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 21.19, NNZs: 50, Bias: -17.000000, T: 251658, Avg. loss: 0.123063\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 21.54, NNZs: 50, Bias: -12.000000, T: 279620, Avg. loss: 0.123682\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 10 epochs took 0.07 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.90, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.229642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.14, NNZs: 50, Bias: -23.000000, T: 55924, Avg. loss: 0.226225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.49, NNZs: 50, Bias: -16.000000, T: 83886, Avg. loss: 0.219831\n",
      "Total training time: 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 4\n",
      "Norm: 27.04, NNZs: 50, Bias: -19.000000, T: 111848, Avg. loss: 0.230682\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.35, NNZs: 50, Bias: -18.000000, T: 139810, Avg. loss: 0.227636\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29.85, NNZs: 50, Bias: -15.000000, T: 167772, Avg. loss: 0.219568\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 34.55, NNZs: 50, Bias: -17.000000, T: 195734, Avg. loss: 0.235954\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 32.31, NNZs: 50, Bias: -16.000000, T: 223696, Avg. loss: 0.225844\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 8 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.43, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.193288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.34, NNZs: 50, Bias: -20.000000, T: 55924, Avg. loss: 0.190061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.24, NNZs: 50, Bias: -19.000000, T: 83886, Avg. loss: 0.196699\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.88, NNZs: 50, Bias: -17.000000, T: 111848, Avg. loss: 0.190262\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.76, NNZs: 50, Bias: -19.000000, T: 139810, Avg. loss: 0.191694\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.23, NNZs: 50, Bias: -21.000000, T: 167772, Avg. loss: 0.192088\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 32.93, NNZs: 50, Bias: -19.000000, T: 195734, Avg. loss: 0.193294\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 7 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.73, NNZs: 50, Bias: -24.000000, T: 27962, Avg. loss: 0.056038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.29, NNZs: 50, Bias: -23.000000, T: 55924, Avg. loss: 0.056693\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.49, NNZs: 50, Bias: -23.000000, T: 83886, Avg. loss: 0.058213\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.14, NNZs: 50, Bias: -23.000000, T: 111848, Avg. loss: 0.056470\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.70, NNZs: 50, Bias: -23.000000, T: 139810, Avg. loss: 0.055790\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.79, NNZs: 50, Bias: -21.000000, T: 167772, Avg. loss: 0.054435\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 25.02, NNZs: 50, Bias: -21.000000, T: 195734, Avg. loss: 0.054522\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 24.16, NNZs: 50, Bias: -25.000000, T: 223696, Avg. loss: 0.056007\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.47, NNZs: 50, Bias: -24.000000, T: 251658, Avg. loss: 0.056386\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 26.27, NNZs: 50, Bias: -27.000000, T: 279620, Avg. loss: 0.053513\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 25.45, NNZs: 50, Bias: -24.000000, T: 307582, Avg. loss: 0.052933\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 11 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.49, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.021751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.19, NNZs: 50, Bias: -24.000000, T: 55924, Avg. loss: 0.021461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.21, NNZs: 50, Bias: -25.000000, T: 83886, Avg. loss: 0.020347\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.77, NNZs: 50, Bias: -28.000000, T: 111848, Avg. loss: 0.023972\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.52, NNZs: 50, Bias: -28.000000, T: 139810, Avg. loss: 0.023329\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.43, NNZs: 50, Bias: -26.000000, T: 167772, Avg. loss: 0.025493\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.33, NNZs: 50, Bias: -28.000000, T: 195734, Avg. loss: 0.022159\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 16.46, NNZs: 50, Bias: -27.000000, T: 223696, Avg. loss: 0.023851\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.02, NNZs: 50, Bias: -18.000000, T: 27962, Avg. loss: 0.096023\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.22, NNZs: 50, Bias: -21.000000, T: 55924, Avg. loss: 0.096710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.52, NNZs: 50, Bias: -19.000000, T: 83886, Avg. loss: 0.096128\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.18, NNZs: 50, Bias: -20.000000, T: 111848, Avg. loss: 0.098432\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.86, NNZs: 50, Bias: -24.000000, T: 139810, Avg. loss: 0.095951\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.20, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.100165\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 16.12, NNZs: 50, Bias: -20.000000, T: 27962, Avg. loss: 0.079561\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.55, NNZs: 50, Bias: -25.000000, T: 55924, Avg. loss: 0.081820\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.83, NNZs: 50, Bias: -22.000000, T: 83886, Avg. loss: 0.080484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.22, NNZs: 50, Bias: -22.000000, T: 111848, Avg. loss: 0.082886\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.25, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.088221\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.33, NNZs: 50, Bias: -24.000000, T: 167772, Avg. loss: 0.083941\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.49, NNZs: 50, Bias: -23.000000, T: 27962, Avg. loss: 0.103708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.03, NNZs: 50, Bias: -28.000000, T: 55924, Avg. loss: 0.105810\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.13, NNZs: 50, Bias: -30.000000, T: 83886, Avg. loss: 0.115024\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.62, NNZs: 50, Bias: -28.000000, T: 111848, Avg. loss: 0.109977\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.73, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.113597\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.74, NNZs: 50, Bias: -25.000000, T: 167772, Avg. loss: 0.107480\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.28, NNZs: 50, Bias: -19.000000, T: 27962, Avg. loss: 0.133973\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.77, NNZs: 50, Bias: -20.000000, T: 55924, Avg. loss: 0.136932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.98, NNZs: 50, Bias: -20.000000, T: 83886, Avg. loss: 0.129894\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.66, NNZs: 50, Bias: -18.000000, T: 111848, Avg. loss: 0.135757\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.45, NNZs: 50, Bias: -20.000000, T: 139810, Avg. loss: 0.131549\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.46, NNZs: 50, Bias: -20.000000, T: 167772, Avg. loss: 0.134635\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.07, NNZs: 50, Bias: -19.000000, T: 195734, Avg. loss: 0.132740\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 20.47, NNZs: 50, Bias: -17.000000, T: 223696, Avg. loss: 0.136699\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 8 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.89, NNZs: 50, Bias: -22.000000, T: 27962, Avg. loss: 0.081857\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.83, NNZs: 50, Bias: -18.000000, T: 55924, Avg. loss: 0.084448\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.73, NNZs: 50, Bias: -19.000000, T: 83886, Avg. loss: 0.084744\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.11, NNZs: 50, Bias: -25.000000, T: 111848, Avg. loss: 0.082488\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.39, NNZs: 50, Bias: -22.000000, T: 139810, Avg. loss: 0.084999\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.93, NNZs: 50, Bias: -22.000000, T: 167772, Avg. loss: 0.085221\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 29.65, NNZs: 50, Bias: 4.000000, T: 27962, Avg. loss: 0.961092\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.74, NNZs: 50, Bias: 3.000000, T: 55924, Avg. loss: 0.962623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.98, NNZs: 50, Bias: 2.000000, T: 83886, Avg. loss: 0.954440\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.51, NNZs: 50, Bias: 0.000000, T: 111848, Avg. loss: 0.952894\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.89, NNZs: 50, Bias: 5.000000, T: 139810, Avg. loss: 0.966340\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.05, NNZs: 50, Bias: 1.000000, T: 167772, Avg. loss: 0.964441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 46.96, NNZs: 50, Bias: -1.000000, T: 195734, Avg. loss: 0.981256\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 49.65, NNZs: 50, Bias: 3.000000, T: 223696, Avg. loss: 0.968299\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 50.63, NNZs: 50, Bias: 2.000000, T: 251658, Avg. loss: 0.957642\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 9 epochs took 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, max_iter=50)\n",
    "calibrated_clf_per = CalibratedClassifierCV(base_estimator=per)\n",
    "calibrated_clf_per.fit(X_train, y_train)\n",
    "y_pred_per = calibrated_clf_per.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa =PassiveAggressiveClassifier()\n",
    "calibrated_clf_pa = CalibratedClassifierCV(base_estimator=pa)\n",
    "calibrated_clf_pa.fit(X_train, y_train)\n",
    "y_pred_pa = calibrated_clf_pa.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11651, 13)\n",
      "(11651, 13)\n",
      "(11651, 13)\n",
      "(11651, 13)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_knn.shape)\n",
    "print(y_pred_rf.shape)\n",
    "print(y_pred_per.shape)\n",
    "print(y_pred_pa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(neigh.classes_) == all(calibrated_clf_pa.classes_) == all(calibrated_clf_per.classes_) == all(randomForest.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as before we are going to evaluate the model on the F1 score using all classes except 'O'\n",
    "all_classes = list(np.unique(y_train))\n",
    "\n",
    "new_classes = all_classes.copy()\n",
    "\n",
    "new_classes.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the predictions from the 4 models above, calculate the average of all and return the class with the highest probability\n",
    "def ensemble_predict(pred_knn,pred_rf,pred_per,pred_pa,groundTruth):\n",
    "\n",
    "    mean_pred = np.mean([pred_knn,pred_rf,pred_per,pred_pa], axis=0)\n",
    "\n",
    "    return randomForest.classes_[np.argmax(mean_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHIT\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#loop over all the predictions from the 4 models and get the final prediction\n",
    "predictions=[]\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "    groundTruth = y_val[i]\n",
    "    pred_knn,pred_rf,pred_per,pred_pa = y_pred_knn[i],y_pred_rf[i],y_pred_per[i],y_pred_pa[i]\n",
    "    predictions.append(ensemble_predict(pred_knn,pred_rf,pred_per,pred_pa,groundTruth))\n",
    "    \n",
    "predictions=np.array(predictions)\n",
    "\n",
    "report = classification_report(y_val, predictions, digits=4,labels=new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation     0.9412    0.3265    0.4848        49\n",
      "B-creative-work     0.0000    0.0000    0.0000        38\n",
      "        B-group     0.3333    0.0175    0.0333        57\n",
      "     B-location     0.8125    0.1024    0.1818       127\n",
      "       B-person     0.8026    0.3742    0.5105       163\n",
      "      B-product     1.0000    0.1935    0.3243        31\n",
      "  I-corporation     0.0000    0.0000    0.0000        12\n",
      "I-creative-work     0.0000    0.0000    0.0000        54\n",
      "        I-group     0.0000    0.0000    0.0000        27\n",
      "     I-location     0.4000    0.0308    0.0571        65\n",
      "       I-person     0.8462    0.1375    0.2366        80\n",
      "      I-product     0.0000    0.0000    0.0000        42\n",
      "\n",
      "      micro avg     0.8088    0.1477    0.2497       745\n",
      "      macro avg     0.4280    0.0985    0.1524       745\n",
      "   weighted avg     0.5689    0.1477    0.2210       745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#overall ensemble learning didn't do very well having a F1 score of just 0.22\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
